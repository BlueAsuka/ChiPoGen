{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/poetry.txt', 'r', encoding='utf-8') as f:\n",
    "    poetry_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the text: 70631298\n"
     ]
    }
   ],
   "source": [
    "print(f'The length of the text: {len(poetry_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'云髻高梳鬓不分，扫除虚室事元君。\\n新糊白纸屏风上，尽画蓬莱五色云。\\n\\n山色摇光入袖凉，松阴十丈印回廊'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_text = poetry_text[:50]\n",
    "temp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(list(set(poetry_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars number: 12966\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokens)\n",
    "print(f'Total chars number: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jieba\n",
    "\n",
    "# print(\"Accurate mode: \")\n",
    "# print(f'{[t for t in jieba.cut(temp_text, cut_all=False)]}')\n",
    "# print()\n",
    "# print(\"Full mode: \")\n",
    "# print(f'{[t for t in jieba.cut(temp_text, cut_all=True)]}')\n",
    "# print()\n",
    "# print(\"Search mode: \")\n",
    "# print(f'{[t for t in jieba.cut_for_search(temp_text)]}')\n",
    "# Use accurate model to tokenize the text\n",
    "\n",
    "# poetry_text_tokens = [token for token in jieba.cut(poetry_text, cut_all=False)]\n",
    "# print(f'Total tokens: {len(poetry_text_tokens)}')\n",
    "# tokens = sorted(list(set(poetry_text_tokens)))\n",
    "# vocab_size = len(tokens)\n",
    "# print(f'Total tokens: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { w:i for i,w in enumerate(tokens)}\n",
    "itos = { i:w for i,w in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1346, 12293, 12276, 5304, 12309, 1267, 1867, 12953, 4338, 11691, 9649, 3245, 1341, 1750, 2181, 44, 0, 4822, 8254, 7298, 8423, 3350, 12016, 1264, 12953, 3337, 7114, 9470, 9285, 1348, 9048, 1346, 44, 0, 0, 3370, 9048, 4648, 1755, 1766, 10005, 1831, 12953, 5106, 11659, 2033, 1262, 2067, 2605, 3751]\n"
     ]
    }
   ],
   "source": [
    "print(encode(temp_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "云髻高梳鬓不分，扫除虚室事元君。\n",
      "新糊白纸屏风上，尽画蓬莱五色云。\n",
      "\n",
      "山色摇光入袖凉，松阴十丈印回廊\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(temp_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70631298]) <built-in method type of Tensor object at 0x0000016691E405E0>\n",
      "tensor([ 1346, 12293, 12276,  5304, 12309,  1267,  1867, 12953,  4338, 11691,\n",
      "         9649,  3245,  1341,  1750,  2181,    44,     0,  4822,  8254,  7298,\n",
      "         8423,  3350, 12016,  1264, 12953,  3337,  7114,  9470,  9285,  1348,\n",
      "         9048,  1346,    44,     0,     0,  3370,  9048,  4648,  1755,  1766,\n",
      "        10005,  1831, 12953,  5106, 11659,  2033,  1262,  2067,  2605,  3751,\n",
      "           44,     0,  8675,  1706, 10392,  8573,  5403,  1286,  2267, 12953,\n",
      "         1257,  5681,  7762, 12016,  5161,  3189, 12113,    44,     0,     0,\n",
      "         8446,  5024,  4132, 11612, 11759, 12953,  4822,  3696,  9141,  3908,\n",
      "         2181,    44,     0, 11826,  2041,  1299,  3243,  1308, 12953,  7298,\n",
      "         2128,  9381,  1330,  1987,    44,     0, 11167,  1773, 11079,  1706])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(poetry_text), dtype=torch.long)\n",
    "print(data.shape, data.type)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenization result\n",
    "# torch.save(data, '../data/poetry_tokens_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data) # The length of the whole dataset\n",
    "train_val_ratio = 0.9\n",
    "train_data = data[:int(train_val_ratio * n)]\n",
    "val_data = data[int(train_val_ratio * n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 63568168\n",
      "Val data size : 7063130\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data size: {len(train_data)}')\n",
    "print(f'Val data size : {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to bin files\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "train_ids = np.array(train_data, dtype=np.uint16)\n",
    "val_ids = np.array(val_data, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids.tofile('../data/train.bin')\n",
    "val_ids.tofile('../data/val.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
