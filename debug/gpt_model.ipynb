{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.memmap('../data/train.bin', dtype=np.uint16, mode='r')\n",
    "val_data = np.memmap('../data/val.bin', dtype=np.uint16, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 32\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Randomly select chunk of text for training\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy(data[i:i+block_size].astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy(data[i+1:i+1+block_size].astype(np.int64)) for i in ix])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5025,  3703, 10124,    44,     0,     0,  3695,  7094,  7373, 10339,\n",
       "          2125, 12953,  2903,  3189,  3240,  2208,  3628,    44,     0,  4770,\n",
       "         10931, 10202,  3921,  1868, 12953,  6078,  4118, 10520,  4307,  5040,\n",
       "            44,     0],\n",
       "        [ 6489,  9283,  3728,  7692, 11391, 11432, 12953,  1920, 10237,  1434,\n",
       "          3921,  8405,  4454, 11250,    44,     0, 10317,  2130,  2050,  3370,\n",
       "          6444,  1788,  6428, 12953,  7299,  3696,  6109,  4968, 10143,  2956,\n",
       "          1387,    44],\n",
       "        [   44,     0,  1282,  1282,  5602,  8465,  2605,  4798,  3195,    44,\n",
       "             0, 12631, 11737,  1267,  3835,  5088,    44,     0,  2146,  2947,\n",
       "          3905,  1264,  6794,    44,     0,  8966,  3968,  8901,  1836,  4856,\n",
       "            44,     0],\n",
       "        [ 5095,    44,     0,  5917, 11593,  1337,  1267,  1774, 12953,  7298,\n",
       "          1346,  1480,  4867,  2605, 12956,     0,  9078,  9447,  1361,  9098,\n",
       "          2968, 12953, 10863,  5984,  5693,  4277,  5734,    44,     0,  2482,\n",
       "          3313, 11022],\n",
       "        [11996,  4374, 12953,  5996,  9856,  4276, 11761, 12953,  6223,  2744,\n",
       "          1833, 11769,    44,     0,  3867,  7534, 10931,  1771, 12953, 10931,\n",
       "          1771,  3867,  7534, 12953,  2900,  2651, 10923,  8515, 11083,  8450,\n",
       "          1621,    44],\n",
       "        [12027,  4838, 10602,  5814, 12028,  7298,    44,     0,  9220,  5073,\n",
       "          2895,  7827,  9398,  2262, 12702,    44,     0,  3243, 10681,  1261,\n",
       "          3370, 11572,    44,     0, 12193,  2527,  7826,  4854, 12718,    44,\n",
       "             0,  7640],\n",
       "        [ 4277,  1361,  1357,  3259,  3189, 12953,  3987,  1299,  2181,  6854,\n",
       "          1796,  5640,  5088,    44,     0,  8528,  8500,  1915, 10985, 10681,\n",
       "          5602, 10963, 12953, 12728,  1346,  7126, 11759,  2603,  5073,  1473,\n",
       "            44,     0],\n",
       "        [11028,  8013,  5619,  1487, 11610, 12953,  4277,  6647,  1814,  2876,\n",
       "          6763,  9957,    44,     0,  1772,  5752,  1462,  2966,  8491,  9968,\n",
       "         12953,  9222,  5974,  5012,  4648,  8401,  5976,    44,     0, 10877,\n",
       "          8996,  5773],\n",
       "        [ 5875,  4026,    44,     0,  3694,  3306,  4818,  5039,  9306, 12953,\n",
       "          5017,  1267,  1968, 12090,  1952,    44,     0,  2643,  7306,  2624,\n",
       "          8971,  5844, 12953,  4854,  4876,  1267, 11020, 12029,    44,     0,\n",
       "          6489,  1769],\n",
       "        [ 4073,    44,     0,  1330,  1917,  1653,  5088,  4826, 10945, 12211,\n",
       "         12953,  3251,  2839,  5017, 10325,  4332,  5925, 11409,    44,     0,\n",
       "          1773,  7535,  1276,  1412,  4883, 12725,  4805, 12953,  3225,  3882,\n",
       "          1346,  1390],\n",
       "        [11248,    44,     0,     0,  2181, 12193, 12718, 12953,  8961, 12193,\n",
       "         10588, 12953, 11956,  8977, 12197, 12224,  2234,  1768,  5108,    44,\n",
       "             0,  3732,  4878,  3485, 12953,  7839,  5944,  5814,    44,     0,\n",
       "          3257,  6854],\n",
       "        [11474,  6484, 12953,  8653,  3669,  7114, 11634, 12953,  1261,  8401,\n",
       "          1340,  2966,    44,     0, 11062,  5012,  6078,  3258, 12953,  3276,\n",
       "          1755,  3701,  1857,  6087, 11121,  3725,    44,     0,  3156,  3057,\n",
       "         10675,  3857],\n",
       "        [10945, 12953,  3850,  8035,  1850,  5311,  6470, 12953,  1915, 10965,\n",
       "         11246, 10306,    44,     0,  4127,  3701,  9197,  6487, 12953,  6686,\n",
       "          4088,  9245, 10068, 12953,  4511,  3337,  4851,  2172,  3204,  4152,\n",
       "            44,     0],\n",
       "        [ 2113, 12953,  6470,  7590,  2900,  1772,  2744,    44,     0,     0,\n",
       "         10930, 10992, 11918,  1755, 12953,  1549,  6531, 10931,  1337, 12953,\n",
       "          8094,  5088,  1882,  7091,  1964,  1968,    44,     0,  8401, 11988,\n",
       "          9978,  5061],\n",
       "        [12956,     0,  5691,  3939, 11022,  1375,  3806,  1257,  4851, 12953,\n",
       "          1366,  3315,  2814,  7420, 12274, 12269,  5140,    44,     0,  3628,\n",
       "         10556, 10548,  3256,  4851,  1375,  6933, 12953, 10520,  3189,  6087,\n",
       "          1755,  7298],\n",
       "        [ 1267,  4152,  2119,  5053,  5492, 12953,  3219,  7090,  6081,  5045,\n",
       "          8481,    44,     0, 11191, 11239,  6291,  2909,  9048, 12953, 10720,\n",
       "         10774,  4782,  3613,  8770,    44,     0,  8285,  5187,  3969,  4373,\n",
       "         10965, 12953]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3703, 10124,    44,     0,     0,  3695,  7094,  7373, 10339,  2125,\n",
       "         12953,  2903,  3189,  3240,  2208,  3628,    44,     0,  4770, 10931,\n",
       "         10202,  3921,  1868, 12953,  6078,  4118, 10520,  4307,  5040,    44,\n",
       "             0,  1346],\n",
       "        [ 9283,  3728,  7692, 11391, 11432, 12953,  1920, 10237,  1434,  3921,\n",
       "          8405,  4454, 11250,    44,     0, 10317,  2130,  2050,  3370,  6444,\n",
       "          1788,  6428, 12953,  7299,  3696,  6109,  4968, 10143,  2956,  1387,\n",
       "            44,     0],\n",
       "        [    0,  1282,  1282,  5602,  8465,  2605,  4798,  3195,    44,     0,\n",
       "         12631, 11737,  1267,  3835,  5088,    44,     0,  2146,  2947,  3905,\n",
       "          1264,  6794,    44,     0,  8966,  3968,  8901,  1836,  4856,    44,\n",
       "             0,  2071],\n",
       "        [   44,     0,  5917, 11593,  1337,  1267,  1774, 12953,  7298,  1346,\n",
       "          1480,  4867,  2605, 12956,     0,  9078,  9447,  1361,  9098,  2968,\n",
       "         12953, 10863,  5984,  5693,  4277,  5734,    44,     0,  2482,  3313,\n",
       "         11022,  2870],\n",
       "        [ 4374, 12953,  5996,  9856,  4276, 11761, 12953,  6223,  2744,  1833,\n",
       "         11769,    44,     0,  3867,  7534, 10931,  1771, 12953, 10931,  1771,\n",
       "          3867,  7534, 12953,  2900,  2651, 10923,  8515, 11083,  8450,  1621,\n",
       "            44,     0],\n",
       "        [ 4838, 10602,  5814, 12028,  7298,    44,     0,  9220,  5073,  2895,\n",
       "          7827,  9398,  2262, 12702,    44,     0,  3243, 10681,  1261,  3370,\n",
       "         11572,    44,     0, 12193,  2527,  7826,  4854, 12718,    44,     0,\n",
       "          7640,  4488],\n",
       "        [ 1361,  1357,  3259,  3189, 12953,  3987,  1299,  2181,  6854,  1796,\n",
       "          5640,  5088,    44,     0,  8528,  8500,  1915, 10985, 10681,  5602,\n",
       "         10963, 12953, 12728,  1346,  7126, 11759,  2603,  5073,  1473,    44,\n",
       "             0,  3370],\n",
       "        [ 8013,  5619,  1487, 11610, 12953,  4277,  6647,  1814,  2876,  6763,\n",
       "          9957,    44,     0,  1772,  5752,  1462,  2966,  8491,  9968, 12953,\n",
       "          9222,  5974,  5012,  4648,  8401,  5976,    44,     0, 10877,  8996,\n",
       "          5773,  7125],\n",
       "        [ 4026,    44,     0,  3694,  3306,  4818,  5039,  9306, 12953,  5017,\n",
       "          1267,  1968, 12090,  1952,    44,     0,  2643,  7306,  2624,  8971,\n",
       "          5844, 12953,  4854,  4876,  1267, 11020, 12029,    44,     0,  6489,\n",
       "          1769, 10936],\n",
       "        [   44,     0,  1330,  1917,  1653,  5088,  4826, 10945, 12211, 12953,\n",
       "          3251,  2839,  5017, 10325,  4332,  5925, 11409,    44,     0,  1773,\n",
       "          7535,  1276,  1412,  4883, 12725,  4805, 12953,  3225,  3882,  1346,\n",
       "          1390,  1281],\n",
       "        [   44,     0,     0,  2181, 12193, 12718, 12953,  8961, 12193, 10588,\n",
       "         12953, 11956,  8977, 12197, 12224,  2234,  1768,  5108,    44,     0,\n",
       "          3732,  4878,  3485, 12953,  7839,  5944,  5814,    44,     0,  3257,\n",
       "          6854,  5690],\n",
       "        [ 6484, 12953,  8653,  3669,  7114, 11634, 12953,  1261,  8401,  1340,\n",
       "          2966,    44,     0, 11062,  5012,  6078,  3258, 12953,  3276,  1755,\n",
       "          3701,  1857,  6087, 11121,  3725,    44,     0,  3156,  3057, 10675,\n",
       "          3857,  1265],\n",
       "        [12953,  3850,  8035,  1850,  5311,  6470, 12953,  1915, 10965, 11246,\n",
       "         10306,    44,     0,  4127,  3701,  9197,  6487, 12953,  6686,  4088,\n",
       "          9245, 10068, 12953,  4511,  3337,  4851,  2172,  3204,  4152,    44,\n",
       "             0,  5803],\n",
       "        [12953,  6470,  7590,  2900,  1772,  2744,    44,     0,     0, 10930,\n",
       "         10992, 11918,  1755, 12953,  1549,  6531, 10931,  1337, 12953,  8094,\n",
       "          5088,  1882,  7091,  1964,  1968,    44,     0,  8401, 11988,  9978,\n",
       "          5061, 12953],\n",
       "        [    0,  5691,  3939, 11022,  1375,  3806,  1257,  4851, 12953,  1366,\n",
       "          3315,  2814,  7420, 12274, 12269,  5140,    44,     0,  3628, 10556,\n",
       "         10548,  3256,  4851,  1375,  6933, 12953, 10520,  3189,  6087,  1755,\n",
       "          7298,  6852],\n",
       "        [ 4152,  2119,  5053,  5492, 12953,  3219,  7090,  6081,  5045,  8481,\n",
       "            44,     0, 11191, 11239,  6291,  2909,  9048, 12953, 10720, 10774,\n",
       "          4782,  3613,  8770,    44,     0,  8285,  5187,  3969,  4373, 10965,\n",
       "         12953,  2905]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.0\n",
    "bias = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32, 1152])\n",
      "Split the last dimension into q, k, v\n",
      "Shape of q, k, v: torch.Size([16, 32, 384]), torch.Size([16, 32, 384]), torch.Size([16, 32, 384])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn(batch_size, block_size, n_embd)\n",
    "attn = nn.Linear(n_embd, 3 * n_embd, bias=bias)\n",
    "print(attn(x1).shape)\n",
    "print(f'Split the last dimension into q, k, v')\n",
    "q, k, v = torch.split(attn(x1), split_size_or_sections=n_embd, dim=2)\n",
    "print(f'Shape of q, k, v: {q.shape}, {k.shape}, {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of q, k, v: torch.Size([16, 6, 32, 64]), torch.Size([16, 6, 32, 64]), torch.Size([16, 6, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "# calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "q = q.view(batch_size, block_size, n_head, n_embd // n_head).transpose(1, 2)\n",
    "k = k.view(batch_size, block_size, n_head, n_embd // n_head).transpose(1, 2)\n",
    "v = v.view(batch_size, block_size, n_head, n_embd // n_head).transpose(1, 2)\n",
    "print(f'Shape of q, k, v: {q.shape}, {k.shape}, {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "          [1., 1., 1.,  ..., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "mask = torch.tril(torch.ones(block_size, block_size))\n",
    "mask = mask.view(1, 1, block_size, block_size) # Add the batch dimension\n",
    "mask[:, :, :block_size, :block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_proj = nn.Linear(n_embd, n_embd, bias)\n",
    "attn_dropout = nn.Dropout(dropout)\n",
    "resid_dropout = nn.Dropout(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "att = att.masked_fill(mask=(mask[:, :, :block_size, :block_size] == 0), value=float('-inf'))\n",
    "att = F.softmax(att, dim=-1)\n",
    "att = attn_dropout(att)\n",
    "y1 = att @ v # (B, nh, T, T) x (B, nh, T, hs) => (B, nh, T, hs)\n",
    "# (B, nh, T, hs) => (B, T, nh, hs) => (B, T, nh * hs) => (B, T, C)\n",
    "y1 = y1.transpose(1, 2).contiguous().view(batch_size, block_size, n_embd)\n",
    "y1 = c_proj(y1)\n",
    "y1 = resid_dropout(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 384])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building blocks of the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        assert n_embd % n_head == 0, \"The remainder of embedding and head number should be zero.\"\n",
    "        \n",
    "        self.c_attn = nn.Linear(n_embd, 3 * n_embd, bias=bias)\n",
    "        self.c_proj = nn.Linear(n_embd, n_embd, bias=bias)\n",
    "        \n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.register_buffer('bias', torch.tril(torch.ones(block_size, block_size))\n",
    "                                          .view(1, 1, block_size, block_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape # batch_size, sequence length (block_size), embedding dimension (n_embd)\n",
    "        \n",
    "        q, k, v = torch.split(self.c_attn(x), split_size_or_sections=n_embd, dim=2)\n",
    "        q = q.view(B, T, n_head, C // n_head).transpose(1, 2)\n",
    "        k = k.view(B, T, n_head, C // n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, n_head, C // n_head).transpose(1, 2)\n",
    "        \n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(mask=(self.bias[:, :, :block_size, :block_size] == 0), value=float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        \n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        return resid_dropout(c_proj(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(n_dim))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # Bias is not used in this model\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, bias=None, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(n_embd, 4 * n_embd, bias)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * n_embd, n_embd, bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(n_embd)\n",
    "        self.attn = SelfAttention()\n",
    "        self.ln_2 = LayerNorm(n_embd)\n",
    "        self.mlp = MLP()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass of the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 32\n",
    "    vocab_size: int = 12992\n",
    "    n_layer: int = 12\n",
    "    n_head: int = 12\n",
    "    n_embd: int = 384 \n",
    "    dropout: float = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12992, 384]), torch.Size([12992, 384])\n"
     ]
    }
   ],
   "source": [
    "# The embedding layer and final output projection layer are in the same shape\n",
    "# They can share the same weights => weight tying\n",
    "emb_w = nn.Embedding(config.vocab_size, config.n_embd).weight\n",
    "proj_w = nn.Linear(config.n_embd, config.vocab_size, bias=False).weight\n",
    "print(f'{emb_w.shape}, {proj_w.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "wpe = nn.Embedding(config.block_size, config.n_embd)\n",
    "drop = nn.Dropout(config.dropout)\n",
    "self_attn = nn.ModuleList([SelfAttentionBlock() for _ in range(config.n_layer)])\n",
    "ln_f = LayerNorm(config.n_embd)\n",
    "\n",
    "lm_head = nn.Linear(config.n_embd, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, t = x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_emb = wte(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.arange(0, t, dtype=torch.long)\n",
    "pos_emb = wpe(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = drop(tok_emb + pos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in self_attn:\n",
    "    h = block(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ln_f(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7403,  0.2919,  0.8253,  ...,  1.3536,  0.6279,  0.9969],\n",
       "         [-1.3320, -0.0372,  0.7929,  ...,  1.4257, -0.0236, -0.4465],\n",
       "         [ 0.1600,  0.0606, -0.8494,  ...,  0.0821, -1.6503, -0.0502],\n",
       "         ...,\n",
       "         [-0.1120, -0.1676,  0.1251,  ...,  0.2305, -0.0765, -0.1127],\n",
       "         [ 0.4834, -0.6434,  0.0100,  ...,  0.3718,  0.1212, -1.1368],\n",
       "         [ 0.0526,  0.0383,  0.0407,  ..., -0.5134,  1.7667, -1.7377]],\n",
       "\n",
       "        [[ 0.6691, -1.0205, -1.7012,  ..., -0.1609,  0.1108,  0.2928],\n",
       "         [-0.3143,  0.9292,  0.2006,  ...,  0.7758, -0.1992, -0.7312],\n",
       "         [-0.0777, -0.5686, -1.1394,  ..., -0.0989,  0.1733, -0.0890],\n",
       "         ...,\n",
       "         [-0.7618,  0.2117,  0.5519,  ..., -1.3541,  1.7957, -0.4803],\n",
       "         [ 0.6352, -0.7841,  1.1753,  ..., -0.2185,  0.9883,  0.2905],\n",
       "         [ 0.4276,  0.1279,  0.5564,  ...,  0.1594,  1.0094, -2.4802]],\n",
       "\n",
       "        [[ 0.2992,  0.0563, -0.3367,  ..., -0.2081,  0.4746, -0.4614],\n",
       "         [-1.0432,  0.4137,  0.3052,  ..., -0.6764,  0.2948, -0.0576],\n",
       "         [-0.3897, -0.2595, -1.5822,  ...,  0.7169, -0.0381, -1.3307],\n",
       "         ...,\n",
       "         [-0.6093,  0.4053, -0.1677,  ..., -0.3149,  1.8599, -1.0600],\n",
       "         [ 0.2441, -0.6691, -0.1369,  ...,  0.4340,  0.2409, -1.4099],\n",
       "         [-0.2647,  0.0797,  0.0532,  ..., -0.4653,  1.8231, -1.9487]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.7734, -1.3522, -0.1387,  ..., -0.4559,  0.3297, -0.7802],\n",
       "         [-0.1487,  1.0791,  0.4350,  ..., -0.6546,  0.1404, -1.9585],\n",
       "         [-0.6642, -0.5496, -0.8634,  ..., -0.0554, -0.3232, -1.6250],\n",
       "         ...,\n",
       "         [-0.9980,  1.9325, -0.5131,  ..., -0.3194,  2.0451, -1.3422],\n",
       "         [-0.4945, -0.3875, -0.2782,  ..., -0.5963,  0.1984, -0.1201],\n",
       "         [ 0.0236, -1.2422,  1.6032,  ...,  0.0074,  2.1285, -2.5354]],\n",
       "\n",
       "        [[-0.2419, -0.4667,  0.1937,  ..., -0.1884,  0.4003,  0.3952],\n",
       "         [-1.4032,  0.3450,  0.6233,  ..., -0.9849,  0.1371, -0.2103],\n",
       "         [-0.9023, -0.6595, -0.0956,  ...,  0.0403, -0.4910, -0.6505],\n",
       "         ...,\n",
       "         [ 0.1958, -0.0843,  0.3712,  ..., -0.2832,  1.3737,  0.3658],\n",
       "         [ 0.8402, -1.2276, -0.3267,  ..., -0.1199,  0.2166, -0.5592],\n",
       "         [ 0.7767,  0.2062,  2.0644,  ..., -0.9431,  0.2706, -1.5849]],\n",
       "\n",
       "        [[-1.7355, -0.8678, -0.9169,  ..., -0.5832, -0.0960, -0.3099],\n",
       "         [-2.1195, -0.0566,  1.0433,  ..., -0.8708, -0.1739,  0.6372],\n",
       "         [-1.6310,  0.6806, -0.8303,  ..., -0.8188,  0.5463, -1.0169],\n",
       "         ...,\n",
       "         [-0.3343,  0.7861, -0.2692,  ...,  1.4211,  1.2920, -0.6366],\n",
       "         [ 0.6634, -0.5855, -2.0553,  ...,  0.5108, -0.4574,  0.9264],\n",
       "         [ 0.1144,  0.4540,  0.4728,  ..., -1.4895,  1.7957, -2.3767]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 384])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = lm_head(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 12992])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1369, -0.0214, -0.1410,  ...,  0.5903,  0.1987,  0.0593],\n",
       "        [-0.3992, -0.6033, -0.8112,  ...,  0.5634,  0.0331,  0.7070],\n",
       "        [ 0.6359, -0.2673, -0.8278,  ...,  0.5802,  0.8409,  0.7029],\n",
       "        ...,\n",
       "        [-0.3523, -0.1463, -0.6002,  ...,  0.1998, -0.2649, -0.1879],\n",
       "        [ 0.4501, -0.5308,  0.7656,  ..., -0.4483, -0.6711,  0.7724],\n",
       "        [ 0.0777, -0.5441, -1.1556,  ...,  0.2921,  0.2450, -0.0256]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = logits.view(-1, logits.size(-1)) # (B, T, C) => (B * T, C)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1).shape # (B, T, 1) => (B * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.6869, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(logits, y.view(-1), ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = nn.ModuleDict(dict(\n",
    "    wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "    wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "    drop = nn.Dropout(config.dropout),\n",
    "    self_attn_block = nn.ModuleList([SelfAttentionBlock() for _ in range(config.n_layer)]),\n",
    "    ln_f = LayerNorm(config.n_embd)\n",
    "))\n",
    "\n",
    "lm_head = nn.Linear(config.n_embd, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_emb = transformer.wte(x)\n",
    "device = x.device\n",
    "b, t = x.size()\n",
    "pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "pos_emb = transformer.wpe(pos)\n",
    "h = transformer.drop(tok_emb + pos_emb)\n",
    "for block in transformer.self_attn_block:\n",
    "    h = block(h)\n",
    "res = transformer.ln_f(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.6859, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the loss\n",
    "logits = lm_head(res)\n",
    "F.cross_entropy(logits.view(-1, logits.shape[-1]), y.view(-1), ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 12992])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for generation in inference\n",
    "logits = lm_head(res[:, [-1], :])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0], dtype=torch.long).view(-1 ,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, t = x.shape\n",
    "wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "\n",
    "x_tok_emb = wte(x)\n",
    "x_tok_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpe = nn.Embedding(config.block_size, config.n_embd)\n",
    "\n",
    "x_pos_emb = wpe(torch.arange(0, t, dtype=torch.long))\n",
    "x_pos_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h = x_tok_emb + x_pos_emb\n",
    "x_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = nn.Dropout(config.dropout)\n",
    "\n",
    "x_h = drop(x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=False)\n",
    "c_proj = nn.Linear(config.n_embd, config.n_embd, bias=False)\n",
    "attn_dropout = nn.Dropout(config.dropout)\n",
    "proj_dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "mask = torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "mask = mask.view(1, 1, config.block_size, config.block_size) # Add the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 384)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T, C = x_h.shape\n",
    "B, T, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v = c_attn(x_h).split(config.n_embd, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q, k, v shape: torch.Size([1, 1, 384]), torch.Size([1, 1, 384]), torch.Size([1, 1, 384])\n"
     ]
    }
   ],
   "source": [
    "print(f'q, k, v shape: {q.shape}, {k.shape}, {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.view(B, T, config.n_head, C // config.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "q = q.view(B, T, config.n_head, C // config.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "v = v.view(B, T, config.n_head, C // config.n_head).transpose(1, 2) # (B, nh, T, hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q, k, v shape: torch.Size([1, 12, 1, 32]), torch.Size([1, 12, 1, 32]), torch.Size([1, 12, 1, 32])\n"
     ]
    }
   ],
   "source": [
    "print(f'q, k, v shape: {q.shape}, {k.shape}, {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = att.masked_fill(mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = F.softmax(att, dim=-1)\n",
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = attn_dropout(att)\n",
    "att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = att @ v\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = proj_dropout(c_proj(y))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_1 = LayerNorm(config.n_embd)\n",
    "x_h = x_h + ln_1(y)\n",
    "x_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)\n",
    "gelu = nn.GELU()\n",
    "c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)\n",
    "dropout = nn.Dropout(config.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h = c_fc(x_h)\n",
    "x_h = gelu(x_h)\n",
    "x_h = c_proj(x_h)\n",
    "x_h = dropout(x_h)\n",
    "x_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_2 = ln_1 = LayerNorm(config.n_embd)\n",
    "x_h = x_h + ln_2(x_h)\n",
    "x_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 384])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_f = LayerNorm(config.n_embd)\n",
    "\n",
    "res = ln_f(x_h)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12992])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "logits = lm_head(res[:, [-1], :])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12992])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = 1.0\n",
    "logits = logits[:, -1, :] / temperature\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8486]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = F.softmax(logits, dim=-1)\n",
    "idx_next = torch.multinomial(probs, num_samples=1)\n",
    "idx_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
