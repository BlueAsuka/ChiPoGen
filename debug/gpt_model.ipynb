{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.memmap('../data/train.bin', dtype=np.uint16, mode='r')\n",
    "val_data = np.memmap('../data/val.bin', dtype=np.uint16, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 32\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Randomly select chunk of text for training\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy(data[i:i+block_size].astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy(data[i+1:i+block_size+1].astype(np.int64)) for i in ix])\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[51074, 14950,  3433, 44758, 34716, 61692, 10520,  4345, 61349, 41060,\n",
       "            43,     0,   686, 15240, 47569, 61692, 57051, 21346,  8912, 46082,\n",
       "            43,     0, 27979, 60398, 36841, 61692, 41204,  4495, 30576,    43,\n",
       "             0,     0],\n",
       "        [28992, 37126,  2807,    43,     0, 25578,  1461, 46574, 13906, 61692,\n",
       "         51531,    42, 23150,  5469, 45151,    43,     0, 26688,   112, 32708,\n",
       "          4800,    43,     0, 16136, 13023,    43,     0,     0, 37651, 64054,\n",
       "         30871, 61692],\n",
       "        [    0, 25916, 20450, 54116, 60904, 61692,  7053, 52273,  7365, 20039,\n",
       "         28585,    43,     0,     0, 39440, 31169,  1778, 16719, 61692, 47588,\n",
       "         64852,  3124, 63630,    43,     0, 10869, 45115, 21605, 16515, 61692,\n",
       "         38578, 40827],\n",
       "        [   43,     0,     0, 28988, 35002, 13872, 61692, 23291,    43,     0,\n",
       "         34007, 55541, 45623, 61692, 55206, 17933, 50899,    43,     0, 24854,\n",
       "         28388, 33048, 61692,  6332, 44038, 55785,    43,     0, 27642, 33541,\n",
       "         23150, 61692],\n",
       "        [25219, 36977, 55958, 61692, 59324, 19406, 55043,    43,     0, 21381,\n",
       "         63800, 21259, 29990, 61692,  1768, 20539, 56860, 51764,    43,     0,\n",
       "         15516, 37558, 15376, 61692, 56769, 55537, 36367,    43,     0,  9691,\n",
       "         30762, 46550],\n",
       "        [46944, 34048, 18083, 58761, 61692,   909, 18204,  6660, 22368,    43,\n",
       "             0,  4616, 15677, 37048, 38477, 61692,  3822, 53331, 16631, 33520,\n",
       "         25645, 24263,    43,     0,     0, 35930, 38394, 44328,   887, 61692,\n",
       "         24984, 28773],\n",
       "        [65412, 56503,   432, 61692, 18645, 60361,    43,     0, 46033, 20039,\n",
       "          2898, 61692, 17163,  2754, 50604,    43,     0, 23336, 42777, 55915,\n",
       "         61692,  7053, 54462, 24747, 12924,    43,     0,  8332, 12894, 61692,\n",
       "          7750, 47415],\n",
       "        [ 2111, 61692,  5187, 30255, 28802,    43,     0, 45034, 64687, 26318,\n",
       "         61692, 32080, 52907, 20797, 53046,    43,     0, 43587, 37787, 13876,\n",
       "         61692,  6541, 38285,    43,     0,  5559, 40898, 25645,  2669, 61692,\n",
       "         16408,  3550],\n",
       "        [61692,  1805, 30784, 28431, 17033, 62625,    43,     0,  7894, 26227,\n",
       "         28819, 61692, 18499, 21372, 22689, 40272,    43,     0, 33615, 46082,\n",
       "         26217, 19649, 61692, 60646, 10468, 55563,    43,     0,  6923, 45851,\n",
       "         61692, 22771],\n",
       "        [36992,    43,     0,     0,  4333,  7160, 61692, 54863, 55654, 30433,\n",
       "         28714,    43,     0, 37663, 14190, 26828, 19273, 61692, 33452, 42336,\n",
       "          2137, 50621,    43,     0, 48279, 56530, 50306, 50532, 61692, 38620,\n",
       "         21399, 17284],\n",
       "        [ 1636, 61692, 60628, 48797,  8782, 22368,    43,     0, 36256, 28965,\n",
       "         47189,  1256, 13949, 33805, 61692,  1880, 11220, 46461,    43,     0,\n",
       "         10557, 42673, 24133, 27194, 61692, 13957, 47415, 55736, 50261,    43,\n",
       "             0, 29124],\n",
       "        [61692,  5190, 50560, 27726, 46151,    43,     0,     0,  3638,  6549,\n",
       "          2306, 43629, 61692,  9569, 39983, 56314,    43,     0, 36897,  1679,\n",
       "         57032, 55155, 61692, 29026, 14041, 24098,    43,     0, 39308, 41595,\n",
       "         59080, 10192],\n",
       "        [   43,     0, 60122,  7867, 46989, 61692, 31979, 15198,  8399, 59065,\n",
       "         19503,    43,     0,  6583, 63230, 65157, 61692, 64655, 52750,  9638,\n",
       "         45809,    43,     0, 35221, 55963, 22062, 22062, 61692, 30568, 61613,\n",
       "         29468,    43],\n",
       "        [10156, 61692, 27283, 10007, 54336,    43,     0, 41715, 35040, 55854,\n",
       "         34780, 61692, 21346, 30272, 32391, 34383, 29023,    43,     0,     0,\n",
       "         13699,  7128,  1256, 59583, 61692,  1077, 53350,  4251,    43,     0,\n",
       "          7566,  8756],\n",
       "        [50286,    43,     0,  4750, 47345, 61692, 53944, 23297, 61692, 46305,\n",
       "         19055, 27456, 47087,    43,     0, 34097, 21154, 61692, 38031, 41858,\n",
       "         22867,    43,     0,  7676, 27682, 17933, 58747, 61692, 13633,  3527,\n",
       "         61692, 21320],\n",
       "        [24451, 61692, 12953,  8669,  1532,    43,     0, 16454, 56503, 13995,\n",
       "          8186, 61692, 22919, 20486, 60114,    43,     0,     0, 42622, 45676,\n",
       "         61692, 53151, 61691, 17549,    43,     0, 44773, 45522, 39994, 61692,\n",
       "         56446, 18063]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_dim, bias) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(n_dim))\n",
    "        self.bias = nn.Parameter(torch.zeros(n_dim)) if bias else None\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
