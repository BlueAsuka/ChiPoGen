{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw_data/poetry.txt', 'r', encoding='utf-8') as f:\n",
    "    poetry_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the text: 70631297\n"
     ]
    }
   ],
   "source": [
    "print(f'The length of the text: {len(poetry_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'云髻高梳鬓不分，扫除虚室事元君。\\n新糊白纸屏风上，尽画蓬莱五色云。\\n\\n山色摇光入袖凉，松阴十丈印回廊'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_text = poetry_text[:50]\n",
    "temp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars number: 12966\n"
     ]
    }
   ],
   "source": [
    "tokens = sorted(list(set(poetry_text)))\n",
    "vocab_size = len(tokens)\n",
    "print(f'Total chars number: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/tokens.pkl', 'wb') as f:\n",
    "    pickle.dump(tokens, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jieba\n",
    "\n",
    "# print(\"Accurate mode: \")\n",
    "# print(f'{[t for t in jieba.cut(temp_text, cut_all=False)]}')\n",
    "# print()\n",
    "# print(\"Full mode: \")\n",
    "# print(f'{[t for t in jieba.cut(temp_text, cut_all=True)]}')\n",
    "# print()\n",
    "# print(\"Search mode: \")\n",
    "# print(f'{[t for t in jieba.cut_for_search(temp_text)]}')\n",
    "# Use accurate model to tokenize the text\n",
    "\n",
    "# poetry_text_tokens = [token for token in jieba.cut(poetry_text, cut_all=False)]\n",
    "# print(f'Total tokens: {len(poetry_text_tokens)}')\n",
    "# tokens = sorted(list(set(poetry_text_tokens)))\n",
    "# vocab_size = len(tokens)\n",
    "# print(f'Total tokens: {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { w:i for i,w in enumerate(tokens)}\n",
    "itos = { i:w for i,w in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1346, 12293, 12276, 5304, 12309, 1267, 1867, 12953, 4338, 11691, 9649, 3245, 1341, 1750, 2181, 44, 0, 4822, 8254, 7298, 8423, 3350, 12016, 1264, 12953, 3337, 7114, 9470, 9285, 1348, 9048, 1346, 44, 0, 0, 3370, 9048, 4648, 1755, 1766, 10005, 1831, 12953, 5106, 11659, 2033, 1262, 2067, 2605, 3751]\n"
     ]
    }
   ],
   "source": [
    "print(encode(temp_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "云髻高梳鬓不分，扫除虚室事元君。\n",
      "新糊白纸屏风上，尽画蓬莱五色云。\n",
      "\n",
      "山色摇光入袖凉，松阴十丈印回廊\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(temp_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encode(poetry_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1346,\n",
       " 12293,\n",
       " 12276,\n",
       " 5304,\n",
       " 12309,\n",
       " 1267,\n",
       " 1867,\n",
       " 12953,\n",
       " 4338,\n",
       " 11691,\n",
       " 9649,\n",
       " 3245,\n",
       " 1341,\n",
       " 1750,\n",
       " 2181,\n",
       " 44,\n",
       " 0,\n",
       " 4822,\n",
       " 8254,\n",
       " 7298,\n",
       " 8423,\n",
       " 3350,\n",
       " 12016,\n",
       " 1264,\n",
       " 12953,\n",
       " 3337,\n",
       " 7114,\n",
       " 9470,\n",
       " 9285,\n",
       " 1348,\n",
       " 9048,\n",
       " 1346,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 3370,\n",
       " 9048,\n",
       " 4648,\n",
       " 1755,\n",
       " 1766,\n",
       " 10005,\n",
       " 1831,\n",
       " 12953,\n",
       " 5106,\n",
       " 11659,\n",
       " 2033,\n",
       " 1262,\n",
       " 2067,\n",
       " 2605,\n",
       " 3751,\n",
       " 44,\n",
       " 0,\n",
       " 8675,\n",
       " 1706,\n",
       " 10392,\n",
       " 8573,\n",
       " 5403,\n",
       " 1286,\n",
       " 2267,\n",
       " 12953,\n",
       " 1257,\n",
       " 5681,\n",
       " 7762,\n",
       " 12016,\n",
       " 5161,\n",
       " 3189,\n",
       " 12113,\n",
       " 44,\n",
       " 0,\n",
       " 0,\n",
       " 8446,\n",
       " 5024,\n",
       " 4132,\n",
       " 11612,\n",
       " 11759,\n",
       " 12953,\n",
       " 4822,\n",
       " 3696,\n",
       " 9141,\n",
       " 3908,\n",
       " 2181,\n",
       " 44,\n",
       " 0,\n",
       " 11826,\n",
       " 2041,\n",
       " 1299,\n",
       " 3243,\n",
       " 1308,\n",
       " 12953,\n",
       " 7298,\n",
       " 2128,\n",
       " 9381,\n",
       " 1330,\n",
       " 1987,\n",
       " 44,\n",
       " 0,\n",
       " 11167,\n",
       " 1773,\n",
       " 11079,\n",
       " 1706]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# data = torch.tensor(encode(poetry_text), dtype=torch.long)\n",
    "# print(data.shape, data.type)\n",
    "# print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenization result\n",
    "# torch.save(data, '../data/poetry_tokens_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data) # The length of the whole dataset\n",
    "train_val_ratio = 0.9\n",
    "train_data = data[:int(train_val_ratio * n)]\n",
    "val_data = data[int(train_val_ratio * n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 63568168\n",
      "Val data size : 7063130\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data size: {len(train_data)}')\n",
    "print(f'Val data size : {len(val_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to bin files\n",
    "import numpy as np\n",
    "\n",
    "train_ids = np.array(train_data, dtype=np.uint16)\n",
    "val_ids = np.array(val_data, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids.tofile('../data/train.bin')\n",
    "val_ids.tofile('../data/val.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.path.exists('../data/tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
